{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOA0D40CGRRFVbvV8N50mY+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Denoising Diffusion Probabilistic Model"],"metadata":{"id":"TfcWnzLpF7hh"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v0ddqmEOlPxa","executionInfo":{"status":"ok","timestamp":1743862230690,"user_tz":-420,"elapsed":2641,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}},"outputId":"f5d4a129-c495-4fbc-998c-b06ee364be1f"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install scipy==1.11.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YbVRubWnSYkL","executionInfo":{"status":"ok","timestamp":1743862247852,"user_tz":-420,"elapsed":17164,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}},"outputId":"fdd01533-9b5b-45dd-d14a-7e38e5790ed4"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scipy==1.11.1\n","  Downloading scipy-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpy<1.28.0,>=1.21.6 (from scipy==1.11.1)\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scipy-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.2/36.2 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy, scipy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.14.1\n","    Uninstalling scipy-1.14.1:\n","      Successfully uninstalled scipy-1.14.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.11.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.26.4 scipy-1.11.1\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn"],"metadata":{"id":"OC7df3O0IKgw","executionInfo":{"status":"ok","timestamp":1743862247889,"user_tz":-420,"elapsed":33,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["## Forward Process"],"metadata":{"id":"d1GV-N0gIpLp"}},{"cell_type":"code","source":["class ForwardProcess(nn.Module):\n","  def __init__(self,\n","              num_time_steps = 1000,\n","              beta_start = 1e-4,\n","              beta_end = 0.02,\n","              ):\n","    super().__init__()\n","    self.betas = torch.linspace(beta_start, beta_end, num_time_steps)\n","    self.alphas = 1 - self.betas\n","    self.alpha_bars = torch.cumprod(self.alphas, dim=0)\n","    self.sqrt_alpha_bars = torch.sqrt(self.alpha_bars)\n","    self.sqrt_one_minus_alpha_bars = torch.sqrt(1 - self.alpha_bars)\n","\n","  def add_noise(self, # add noise to a batch of original images at timestep t\n","                original, # input image tensor\n","                noise, # random noise tensor sampled from N(0, I)\n","                t, # timestep of each images in batch, may differ for each image\n","                ):\n","    sqrt_alpha_bar_t = self.sqrt_alpha_bars.to(original.device)[t]\n","    sqrt_one_minus_alpha_bar_t = self.sqrt_one_minus_alpha_bars.to(original.device)[t]\n","\n","    # broadcast to multiply with original image\n","    sqrt_alpha_bar_t = sqrt_alpha_bar_t[:, None, None, None]\n","    sqrt_one_minus_alpha_bar_t = sqrt_one_minus_alpha_bar_t[:, None, None, None]\n","\n","    return sqrt_alpha_bar_t * original + sqrt_one_minus_alpha_bar_t * noise"],"metadata":{"id":"S06pBmyMF_Ms","executionInfo":{"status":"ok","timestamp":1743862247893,"user_tz":-420,"elapsed":2,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# test\n","original = torch.randn(4, 1, 28, 28)\n","noise = torch.randn(4, 1, 28, 28)\n","t_steps = torch.randint(0, 1000, (4,)) # random 4 int in range [0,1000)\n","\n","# test forward process\n","fp = ForwardProcess()\n","out = fp.add_noise(original, noise, t_steps)\n","print(out.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jj7nPHDPxtA","executionInfo":{"status":"ok","timestamp":1743862247898,"user_tz":-420,"elapsed":4,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}},"outputId":"3568461f-e9cb-42c7-e03a-372e875f93de"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 1, 28, 28])\n"]}]},{"cell_type":"markdown","source":["## Reverse Process"],"metadata":{"id":"x1MGurD4Q-Jq"}},{"cell_type":"code","source":["class ReverseProcess(nn.Module):\n","  def __init__(self,\n","               num_time_steps = 1000,\n","               beta_start = 1e-4,\n","               beta_end = 0.02,\n","               ):\n","    super().__init__()\n","    self.betas = torch.linspace(beta_start, beta_end, num_time_steps)\n","    self.alphas = 1 - self.betas\n","    self.alpha_bars = torch.cumprod(self.alphas, dim=0)\n","\n","  def sample_prev_timestep(self, # sample x_(t-1) given x_t and noise predicted by model\n","                           xt, # image tensor at timestep t\n","                           noise_pred,# noise predicted by model, same shape as xt\n","                           t, # current timestep\n","                           ):\n","    # original image prediction at current timestep t\n","    x0 = xt - (torch.sqrt(1 - self.alpha_bars.to(xt.device)[t]) * noise_pred)\n","    x0 = x0 / torch.sqrt(self.alpha_bars.to(xt.device)[t])\n","    x0 = torch.clamp(x0, -1., 1.)\n","\n","    # mean of x_(t-1)\n","    mean = (xt - ((1 - self.alphas.to(xt.device)[t]) * noise_pred)\n","    / (torch.sqrt(1 - self.alpha_bars.to(xt.device)[t])))\n","\n","    if t==0:\n","      return mean, x0\n","    else:\n","      var = (1 - self.alpha_bars.to(xt.device)[t-1]) / (1 - self.alpha_bars.to(xt.device)[t])\n","      var *= self.betas.to(xt.device)[t]\n","      sigma = var ** 0.5\n","      z = torch.randn(xt.shape).to(xt.device)\n","\n","      return mean + sigma * z, x0\n"],"metadata":{"id":"YRWKlefEQh_a","executionInfo":{"status":"ok","timestamp":1743862247901,"user_tz":-420,"elapsed":2,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# test\n","xt = torch.randn(1, 1, 28, 28) # random xt\n","noise_pred = torch.randn(1, 1, 28, 28) # random noise_pred\n","t = torch.randint(0, 1000, (1,)) # random 4 int in range [0,1000)\n","# test reverse process\n","rp = ReverseProcess()\n","out, x0 = rp.sample_prev_timestep(xt, noise_pred, t)\n","print(out.shape)\n","print(x0.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sKhKYjvcIVWw","executionInfo":{"status":"ok","timestamp":1743862247930,"user_tz":-420,"elapsed":29,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}},"outputId":"f13064db-7d79-4a57-8b05-aa5bff9ca74c"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 1, 28, 28])\n","torch.Size([1, 1, 28, 28])\n"]}]},{"cell_type":"markdown","source":["## Model Architecture"],"metadata":{"id":"x0h-BTuOLIUl"}},{"cell_type":"markdown","source":["### Time Embedding"],"metadata":{"id":"jt5ULm-dLbqS"}},{"cell_type":"code","source":["def get_time_embedding(\n","    time_steps: torch.Tensor, # scalar time-step (batch,)\n","    t_emb_dim: int, # embedding dimension\n",") -> torch.Tensor: # (batch, t_emb_dim)\n","  assert t_emb_dim % 2 == 0, \"time embedding must be divisible by 2.\"\n","  half_dim = t_emb_dim // 2\n","  factor = 2 * torch.arange(start=0,\n","                            end = half_dim,\n","                            dtype=torch.float32,\n","                            device=time_steps.device\n","                            ) / (t_emb_dim)\n","  factor = 10000 ** factor\n","  t_emb = time_steps[:, None] # B -> (B, 1)\n","  t_emb = t_emb / factor # (B, 1) -> (B, half_dim)\n","  t_emb = torch.cat([torch.sin(t_emb), torch.cos(t_emb)], dim=1) # (B, half_dim) -> (B, t_emb_dim)\n","  return t_emb\n"],"metadata":{"id":"tWjmBiUAK_Qf","executionInfo":{"status":"ok","timestamp":1743862247938,"user_tz":-420,"elapsed":7,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["### U-net"],"metadata":{"id":"Vw4_kT_BPt1c"}},{"cell_type":"markdown","source":["#### Utility Modules"],"metadata":{"id":"lhK-UslWP3EI"}},{"cell_type":"code","source":["class NormActConv(nn.Module):\n","    def __init__(self,\n","                 in_channels:int,\n","                 out_channels:int,\n","                 num_groups:int = 8,\n","                 kernel_size: int = 3,\n","                 norm:bool = True,\n","                 act:bool = True\n","                ):\n","        super(NormActConv, self).__init__()\n","\n","        # GroupNorm\n","        self.g_norm = nn.GroupNorm(\n","            num_groups,\n","            in_channels\n","        ) if norm is True else nn.Identity()\n","\n","        # Activation SiLU\n","        self.act = nn.SiLU() if act is True else nn.Identity()\n","\n","        # Convolution\n","        self.conv = nn.Conv2d(\n","            in_channels,\n","            out_channels,\n","            kernel_size,\n","            padding=(kernel_size - 1)//2\n","        )\n","\n","    def forward(self, x):\n","        x = self.g_norm(x)\n","        x = self.act(x)\n","        x = self.conv(x)\n","        return x\n","\n","class TimeEmbedding(nn.Module):\n","    \"\"\"\n","    Maps the Time Embedding to the Required output Dimension.\n","    \"\"\"\n","    def __init__(self,\n","                n_out:int, # Output Dimension\n","                t_emb_dim:int = 128 # Time Embedding Dimension\n","                ):\n","        super(TimeEmbedding, self).__init__()\n","\n","        # Time Embedding Block\n","        self.te_block = nn.Sequential(\n","            nn.SiLU(),\n","            nn.Linear(t_emb_dim, n_out)\n","        )\n","\n","    def forward(self, x):\n","        return self.te_block(x)\n","\n","class SelfAttentionBlock(nn.Module):\n","    \"\"\"\n","    Perform GroupNorm and Multiheaded Self Attention operation.\n","    \"\"\"\n","    def __init__(self,\n","                 num_channels:int,\n","                 num_groups:int = 8,\n","                 num_heads:int = 4,\n","                 norm:bool = True\n","                ):\n","        super(SelfAttentionBlock, self).__init__()\n","\n","        # GroupNorm\n","        self.g_norm = nn.GroupNorm(\n","            num_groups,\n","            num_channels\n","        ) if norm is True else nn.Identity()\n","\n","        # Self-Attention\n","        self.attn = nn.MultiheadAttention(\n","            num_channels,\n","            num_heads,\n","            batch_first=True\n","        )\n","\n","    def forward(self, x):\n","        batch_size, channels, h, w = x.shape\n","        x = x.reshape(batch_size, channels, h*w)\n","        x = self.g_norm(x)\n","        x = x.transpose(1, 2)\n","        x, _ = self.attn(x, x, x)\n","        x = x.transpose(1, 2).reshape(batch_size, channels, h, w)\n","        return x\n","\n","class Downsample(nn.Module):\n","    \"\"\"\n","    Perform Downsampling by the factor of k across Height and Width.\n","    \"\"\"\n","    def __init__(self,\n","                 in_channels:int,\n","                 out_channels:int,\n","                 k:int = 2, # Downsampling factor\n","                 use_conv:bool = True, # If Downsampling using conv-block\n","                 use_mpool:bool = True # If Downsampling using max-pool\n","                ):\n","        super(Downsample, self).__init__()\n","\n","        self.use_conv = use_conv\n","        self.use_mpool = use_mpool\n","\n","        # Downsampling using Convolution\n","        self.cv = nn.Sequential(\n","            nn.Conv2d(in_channels, in_channels, kernel_size=1),\n","            nn.Conv2d(\n","                in_channels,\n","                out_channels//2 if use_mpool else out_channels,\n","                kernel_size=4,\n","                stride=k,\n","                padding=1\n","            )\n","        ) if use_conv else nn.Identity()\n","\n","        # Downsampling using Maxpool\n","        self.mpool = nn.Sequential(\n","            nn.MaxPool2d(k, k),\n","            nn.Conv2d(\n","                in_channels,\n","                out_channels//2 if use_conv else out_channels,\n","                kernel_size=1,\n","                stride=1,\n","                padding=0\n","            )\n","        ) if use_mpool else nn.Identity()\n","\n","    def forward(self, x):\n","\n","        if not self.use_conv:\n","            return self.mpool(x)\n","\n","        if not self.use_mpool:\n","            return self.cv(x)\n","\n","        return torch.cat([self.cv(x), self.mpool(x)], dim=1)\n","\n","class Upsample(nn.Module):\n","    \"\"\"\n","    Perform Upsampling by the factor of k across Height and Width\n","    \"\"\"\n","    def __init__(self,\n","                 in_channels:int,\n","                 out_channels:int,\n","                 k:int = 2, # Upsampling factor\n","                 use_conv:bool = True, # Upsampling using conv-block\n","                 use_upsample:bool = True # Upsampling using nn.upsample\n","                ):\n","        super(Upsample, self).__init__()\n","\n","        self.use_conv = use_conv\n","        self.use_upsample = use_upsample\n","\n","        # Upsampling using conv\n","        self.cv = nn.Sequential(\n","            nn.ConvTranspose2d(\n","                in_channels,\n","                out_channels//2 if use_upsample else out_channels,\n","                kernel_size=4,\n","                stride=k,\n","                padding=1\n","            ),\n","            nn.Conv2d(\n","                out_channels//2 if use_upsample else out_channels,\n","                out_channels//2 if use_upsample else out_channels,\n","                kernel_size = 1,\n","                stride=1,\n","                padding=0\n","            )\n","        ) if use_conv else nn.Identity()\n","\n","        # Upsamling using nn.Upsample\n","        self.up = nn.Sequential(\n","            nn.Upsample(\n","                scale_factor=k,\n","                mode = 'bilinear',\n","                align_corners=False\n","            ),\n","            nn.Conv2d(\n","                in_channels,\n","                out_channels//2 if use_conv else out_channels,\n","                kernel_size=1,\n","                stride=1,\n","                padding=0\n","            )\n","        ) if use_upsample else nn.Identity()\n","\n","    def forward(self, x):\n","\n","        if not self.use_conv:\n","            return self.up(x)\n","\n","        if not self.use_upsample:\n","            return self.cv(x)\n","\n","        return torch.cat([self.cv(x), self.up(x)], dim=1)"],"metadata":{"id":"UohmOYzoPWHi","executionInfo":{"status":"ok","timestamp":1743862247971,"user_tz":-420,"elapsed":39,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["#Test\n","layer = Upsample(16, 32, 2, True, True)\n","x = torch.randn(4, 16, 32, 32)\n","layer(x).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-0X07c-RJG0","executionInfo":{"status":"ok","timestamp":1743862248008,"user_tz":-420,"elapsed":42,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}},"outputId":"71de399a-ff1c-420e-feb4-bcbcfa3cce93"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 32, 64, 64])"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["#### Down-Conv Block"],"metadata":{"id":"Xk9Ted1URfp9"}},{"cell_type":"code","source":["class DownC(nn.Module):\n","    \"\"\"\n","    Perform Down-convolution on the input using following approach.\n","    1. Conv + TimeEmbedding\n","    2. Conv\n","    3. Skip-connection from input x.\n","    4. Self-Attention\n","    5. Skip-Connection from 3.\n","    6. Downsampling\n","    \"\"\"\n","    def __init__(self,\n","                 in_channels:int,\n","                 out_channels:int,\n","                 t_emb_dim:int = 128, # Time Embedding Dimension\n","                 num_layers:int=2,\n","                 down_sample:bool = True # True for Downsampling\n","                ):\n","        super(DownC, self).__init__()\n","\n","        self.num_layers = num_layers\n","\n","        self.conv1 = nn.ModuleList([\n","            NormActConv(in_channels if i==0 else out_channels,\n","                        out_channels\n","                       ) for i in range(num_layers)\n","        ])\n","\n","        self.conv2 = nn.ModuleList([\n","            NormActConv(out_channels,\n","                        out_channels\n","                       ) for _ in range(num_layers)\n","        ])\n","\n","        self.te_block = nn.ModuleList([\n","            TimeEmbedding(out_channels, t_emb_dim) for _ in range(num_layers)\n","        ])\n","\n","        self.attn_block = nn.ModuleList([\n","            SelfAttentionBlock(out_channels) for _ in range(num_layers)\n","        ])\n","\n","        self.down_block =Downsample(out_channels, out_channels) if down_sample else nn.Identity()\n","\n","        self.res_block = nn.ModuleList([\n","            nn.Conv2d(\n","                in_channels if i==0 else out_channels,\n","                out_channels,\n","                kernel_size=1\n","            ) for i in range(num_layers)\n","        ])\n","\n","    def forward(self, x, t_emb):\n","\n","        out = x\n","\n","        for i in range(self.num_layers):\n","            resnet_input = out\n","\n","            # Resnet Block\n","            out = self.conv1[i](out)\n","            out = out + self.te_block[i](t_emb)[:, :, None, None]\n","            out = self.conv2[i](out)\n","            out = out + self.res_block[i](resnet_input)\n","\n","            # Self Attention\n","            out_attn = self.attn_block[i](out)\n","            out = out + out_attn\n","\n","        # Downsampling\n","        out = self.down_block(out)\n","\n","        return out"],"metadata":{"id":"xQ9MwkhNRZau","executionInfo":{"status":"ok","timestamp":1743862248015,"user_tz":-420,"elapsed":7,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["#### Mid-Conv Block"],"metadata":{"id":"OUpjGzlxRqAf"}},{"cell_type":"code","source":["class MidC(nn.Module):\n","    \"\"\"\n","    Refine the features obtained from the DownC block.\n","    It refines the features using following operations:\n","\n","    1. Resnet Block with Time Embedding\n","    2. A Series of Self-Attention + Resnet Block with Time-Embedding\n","    \"\"\"\n","    def __init__(self,\n","                 in_channels:int,\n","                 out_channels:int,\n","                 t_emb_dim:int = 128,\n","                 num_layers:int = 2\n","                ):\n","        super(MidC, self).__init__()\n","\n","        self.num_layers = num_layers\n","\n","        self.conv1 = nn.ModuleList([\n","            NormActConv(in_channels if i==0 else out_channels,\n","                        out_channels\n","                       ) for i in range(num_layers + 1)\n","        ])\n","\n","        self.conv2 = nn.ModuleList([\n","            NormActConv(out_channels,\n","                        out_channels\n","                       ) for _ in range(num_layers + 1)\n","        ])\n","\n","        self.te_block = nn.ModuleList([\n","            TimeEmbedding(out_channels, t_emb_dim) for _ in range(num_layers + 1)\n","        ])\n","\n","        self.attn_block = nn.ModuleList([\n","            SelfAttentionBlock(out_channels) for _ in range(num_layers)\n","        ])\n","\n","        self.res_block = nn.ModuleList([\n","            nn.Conv2d(\n","                in_channels if i==0 else out_channels,\n","                out_channels,\n","                kernel_size=1\n","            ) for i in range(num_layers + 1)\n","        ])\n","\n","    def forward(self, x, t_emb):\n","        out = x\n","\n","        # First-Resnet Block\n","        resnet_input = out\n","        out = self.conv1[0](out)\n","        out = out + self.te_block[0](t_emb)[:, :, None, None]\n","        out = self.conv2[0](out)\n","        out = out + self.res_block[0](resnet_input)\n","\n","        # Sequence of Self-Attention + Resnet Blocks\n","        for i in range(self.num_layers):\n","\n","            # Self Attention\n","            out_attn = self.attn_block[i](out)\n","            out = out + out_attn\n","\n","            # Resnet Block\n","            resnet_input = out\n","            out = self.conv1[i+1](out)\n","            out = out + self.te_block[i+1](t_emb)[:, :, None, None]\n","            out = self.conv2[i+1](out)\n","            out = out + self.res_block[i+1](resnet_input)\n","\n","        return out"],"metadata":{"id":"P7Am3cbCRpeb","executionInfo":{"status":"ok","timestamp":1743862248047,"user_tz":-420,"elapsed":2,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["#### Up-Conv Block"],"metadata":{"id":"YG8DMYk7Ry0l"}},{"cell_type":"code","source":["class UpC(nn.Module):\n","    \"\"\"\n","    Perform Up-convolution on the input using following approach.\n","    1. Upsampling\n","    2. Conv + TimeEmbedding\n","    3. Conv\n","    4. Skip-connection from 1.\n","    5. Self-Attention\n","    6. Skip-Connection from 3.\n","    \"\"\"\n","    def __init__(self,\n","                 in_channels:int,\n","                 out_channels:int,\n","                 t_emb_dim:int = 128, # Time Embedding Dimension\n","                 num_layers:int = 2,\n","                 up_sample:bool = True # True for Upsampling\n","                ):\n","        super(UpC, self).__init__()\n","\n","        self.num_layers = num_layers\n","\n","        self.conv1 = nn.ModuleList([\n","            NormActConv(in_channels if i==0 else out_channels,\n","                        out_channels\n","                       ) for i in range(num_layers)\n","        ])\n","\n","        self.conv2 = nn.ModuleList([\n","            NormActConv(out_channels,\n","                        out_channels\n","                       ) for _ in range(num_layers)\n","        ])\n","\n","        self.te_block = nn.ModuleList([\n","            TimeEmbedding(out_channels, t_emb_dim) for _ in range(num_layers)\n","        ])\n","\n","        self.attn_block = nn.ModuleList([\n","            SelfAttentionBlock(out_channels) for _ in range(num_layers)\n","        ])\n","\n","        self.up_block =Upsample(in_channels, in_channels//2) if up_sample else nn.Identity()\n","\n","        self.res_block = nn.ModuleList([\n","            nn.Conv2d(\n","                in_channels if i==0 else out_channels,\n","                out_channels,\n","                kernel_size=1\n","            ) for i in range(num_layers)\n","        ])\n","\n","    def forward(self, x, down_out, t_emb):\n","\n","        # Upsampling\n","        x = self.up_block(x)\n","        x = torch.cat([x, down_out], dim=1)\n","\n","        out = x\n","        for i in range(self.num_layers):\n","            resnet_input = out\n","\n","            # Resnet Block\n","            out = self.conv1[i](out)\n","            out = out + self.te_block[i](t_emb)[:, :, None, None]\n","            out = self.conv2[i](out)\n","            out = out + self.res_block[i](resnet_input)\n","\n","            # Self Attention\n","            out_attn = self.attn_block[i](out)\n","            out = out + out_attn\n","\n","        return out"],"metadata":{"id":"2n7N9cXPRw9f","executionInfo":{"status":"ok","timestamp":1743862248049,"user_tz":-420,"elapsed":1,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["#### U-net"],"metadata":{"id":"kee7gUeBR9vc"}},{"cell_type":"code","source":["class Unet(nn.Module):\n","    \"\"\"\n","    U-net architecture which is used to predict noise\n","    in the paper \"Denoising Diffusion Probabilistic Model\".\n","\n","    U-net consists of Series of DownC blocks followed by MidC\n","    followed by UpC.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 im_channels: int = 1, # RGB\n","                 down_ch: list = [32, 64, 128, 256],\n","                 mid_ch: list = [256, 256, 128],\n","                 up_ch: list[int] = [256, 128, 64, 16],\n","                 down_sample: list[bool] = [True, True, False],\n","                 t_emb_dim: int = 128,\n","                 num_downc_layers:int = 2,\n","                 num_midc_layers:int = 2,\n","                 num_upc_layers:int = 2\n","                ):\n","        super(Unet, self).__init__()\n","\n","        self.im_channels = im_channels\n","        self.down_ch = down_ch\n","        self.mid_ch = mid_ch\n","        self.up_ch = up_ch\n","        self.t_emb_dim = t_emb_dim\n","        self.down_sample = down_sample\n","        self.num_downc_layers = num_downc_layers\n","        self.num_midc_layers = num_midc_layers\n","        self.num_upc_layers = num_upc_layers\n","\n","        self.up_sample = list(reversed(self.down_sample)) # [False, True, True]\n","\n","        # Initial Convolution\n","        self.cv1 = nn.Conv2d(self.im_channels, self.down_ch[0], kernel_size=3, padding=1)\n","\n","        # Initial Time Embedding Projection\n","        self.t_proj = nn.Sequential(\n","            nn.Linear(self.t_emb_dim, self.t_emb_dim),\n","            nn.SiLU(),\n","            nn.Linear(self.t_emb_dim, self.t_emb_dim)\n","        )\n","\n","        # DownC Blocks\n","        self.downs = nn.ModuleList([\n","            DownC(\n","                self.down_ch[i],\n","                self.down_ch[i+1],\n","                self.t_emb_dim,\n","                self.num_downc_layers,\n","                self.down_sample[i]\n","            ) for i in range(len(self.down_ch) - 1)\n","        ])\n","\n","        # MidC Block\n","        self.mids = nn.ModuleList([\n","            MidC(\n","                self.mid_ch[i],\n","                self.mid_ch[i+1],\n","                self.t_emb_dim,\n","                self.num_midc_layers\n","            ) for i in range(len(self.mid_ch) - 1)\n","        ])\n","\n","        # UpC Block\n","        self.ups = nn.ModuleList([\n","            UpC(\n","                self.up_ch[i],\n","                self.up_ch[i+1],\n","                self.t_emb_dim,\n","                self.num_upc_layers,\n","                self.up_sample[i]\n","            ) for i in range(len(self.up_ch) - 1)\n","        ])\n","\n","        # Final Convolution\n","        self.cv2 = nn.Sequential(\n","            nn.GroupNorm(8, self.up_ch[-1]),\n","            nn.Conv2d(self.up_ch[-1], self.im_channels, kernel_size=3, padding=1)\n","        )\n","\n","    def forward(self, x, t):\n","\n","        out = self.cv1(x)\n","\n","        # Time Projection\n","        t_emb = get_time_embedding(t, self.t_emb_dim)\n","        t_emb = self.t_proj(t_emb)\n","\n","        # DownC outputs\n","        down_outs = []\n","\n","        for down in self.downs:\n","            down_outs.append(out)\n","            out = down(out, t_emb)\n","\n","        # MidC outputs\n","        for mid in self.mids:\n","            out = mid(out, t_emb)\n","\n","        # UpC Blocks\n","        for up in self.ups:\n","            down_out = down_outs.pop()\n","            out = up(out, down_out, t_emb)\n","\n","        # Final Conv\n","        out = self.cv2(out)\n","\n","        return out\n","# Test\n","model = Unet()"],"metadata":{"id":"2prO7joxR4Hr","executionInfo":{"status":"ok","timestamp":1743862248361,"user_tz":-420,"elapsed":311,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# Test\n","model = Unet()\n","x = torch.randn(4, 1, 32, 32)\n","t = torch.randint(0, 10, (4,))\n","model(x, t).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7B8XuwGR9Fi","executionInfo":{"status":"ok","timestamp":1743862250254,"user_tz":-420,"elapsed":1891,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}},"outputId":"b57509d9-b0aa-46b3-be7a-516ad3b0ca9c"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 1, 32, 32])"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"EKqxhymbTVeq"}},{"cell_type":"markdown","source":["### Dataset"],"metadata":{"id":"7cvYr6tQTYiv"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from torch.utils.data import Dataset\n","from torchvision.datasets import MNIST\n","from torchvision import transforms\n","\n","class CustomMnistDataset(Dataset):\n","    \"\"\"\n","    Custom MNIST Dataset không cần đọc CSV, sử dụng torchvision.datasets.MNIST\n","    \"\"\"\n","    def __init__(self, root=\"./data\", train=True, num_datapoints=None):\n","        super(CustomMnistDataset, self).__init__()\n","\n","        # Load MNIST từ torchvision\n","        self.dataset = MNIST(\n","            root=root,\n","            train=train,\n","            download=True,\n","            transform=transforms.Compose([\n","                transforms.ToTensor(),           # [0,1]\n","                transforms.Lambda(lambda x: x * 2 - 1)  # [-1,1]\n","            ])\n","        )\n","\n","        if num_datapoints is not None:\n","            self.dataset.data = self.dataset.data[:num_datapoints]\n","            self.dataset.targets = self.dataset.targets[:num_datapoints]\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        # Chỉ trả về ảnh, không cần label (vì dùng trong Diffusion model)\n","        img, _ = self.dataset[idx]\n","        return img\n"],"metadata":{"id":"XPsaLmyRSHi-","executionInfo":{"status":"ok","timestamp":1743862250280,"user_tz":-420,"elapsed":18,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["### Training-Loop"],"metadata":{"id":"6eEX1IVbUxA_"}},{"cell_type":"code","source":["class CONFIG:\n","    model_path = 'ddpm_unet.pth'\n","    generated_csv_path = '/content/drive/MyDrive/Phase 2/DDPM/ddpm_unet.pth'\n","    num_epochs = 20\n","    lr = 1e-4\n","    num_timesteps = 1000\n","    batch_size = 128\n","    img_size = 28\n","    in_channels = 1\n","    num_img_to_generate = 256\n"],"metadata":{"id":"hLlY4fwzTcrW","executionInfo":{"status":"ok","timestamp":1743862250293,"user_tz":-420,"elapsed":11,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","import torch\n","import numpy as np\n","\n","def train(cfg):\n","    # Dataset and Dataloader\n","    mnist_ds = CustomMnistDataset(root=\"./data\", train=True)  # Chỉnh lại từ tải CSV sang tải từ torchvision\n","    mnist_dl = DataLoader(mnist_ds, cfg.batch_size, shuffle=True)\n","\n","    # Device\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    print(f'Device: {device}\\n')\n","\n","    # Initiate Model\n","    model = Unet().to(device)\n","\n","    # Initialize Optimizer and Loss Function\n","    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)\n","    criterion = torch.nn.MSELoss()\n","\n","    # Diffusion Forward Process to add noise\n","    dfp = ForwardProcess()\n","\n","    # Best Loss\n","    best_eval_loss = float('inf')\n","\n","    # Train\n","    for epoch in range(cfg.num_epochs):\n","\n","        # For Loss Tracking\n","        losses = []\n","\n","        # Set model to train mode\n","        model.train()\n","\n","        # Loop over dataloader\n","        for imgs in tqdm(mnist_dl):\n","\n","            imgs = imgs.to(device)\n","\n","            # Generate noise and timestamps\n","            noise = torch.randn_like(imgs).to(device)\n","            t = torch.randint(0, cfg.num_timesteps, (imgs.shape[0],)).to(device)\n","\n","            # Add noise to the images using Forward Process\n","            noisy_imgs = dfp.add_noise(imgs, noise, t)\n","\n","            # Avoid Gradient Accumulation\n","            optimizer.zero_grad()\n","\n","            # Predict noise using U-net Model\n","            noise_pred = model(noisy_imgs, t)\n","\n","            # Calculate Loss\n","            loss = criterion(noise_pred, noise)\n","            losses.append(loss.item())\n","\n","            # Backprop + Update model params\n","            loss.backward()\n","            optimizer.step()\n","\n","        # Mean Loss\n","        mean_epoch_loss = np.mean(losses)\n","\n","        # Display\n","        print('Epoch:{} | Loss : {:.4f}'.format(\n","            epoch + 1,\n","            mean_epoch_loss,\n","        ))\n","\n","        # Save based on train-loss\n","        if mean_epoch_loss < best_eval_loss:\n","            best_eval_loss = mean_epoch_loss\n","            torch.save(model.state_dict(), cfg.model_path)  # Save state_dict thay vì model hoàn chỉnh\n","\n","    print(f'Done training...')\n"],"metadata":{"id":"kquE21-TUrLC","executionInfo":{"status":"ok","timestamp":1743862250322,"user_tz":-420,"elapsed":5,"user":{"displayName":"Huy Nguyễn Hữu","userId":"04111097095290696206"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# Config\n","cfg = CONFIG()\n","\n","# TRAIN\n","train(cfg)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o_Co7tOgU0er","outputId":"2617d364-b880-4a6c-b641-afe408c01132"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cpu\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/469 [00:00<?, ?it/s]"]}]},{"cell_type":"code","source":["def generate(cfg):\n","    \"\"\"\n","    Given Pretrained DDPM U-net model, Generate Real-life\n","    Images from noise by going backward step by step. i.e.,\n","    Mapping of Random Noise to Real-life images.\n","    \"\"\"\n","\n","    # Device\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    #print(f'Device: {device}\\n')\n","\n","    # Initialize Diffusion Reverse Process\n","    drp = ReverseProcess()\n","\n","    # Set model to eval mode\n","    model = torch.load(cfg.model_path).to(device)\n","    model.eval()\n","\n","    # Generate Noise sample from N(0, 1)\n","    xt = torch.randn(1, cfg.in_channels, cfg.img_size, cfg.img_size).to(device)\n","\n","    # Denoise step by step by going backward.\n","    with torch.no_grad():\n","        for t in reversed(range(cfg.num_timesteps)):\n","            noise_pred = model(xt, torch.as_tensor(t).unsqueeze(0).to(device))\n","            xt, x0 = drp.sample_prev_timestep(xt, noise_pred, torch.as_tensor(t).to(device))\n","\n","    # Convert the image to proper scale\n","    xt = torch.clamp(xt, -1., 1.).detach().cpu()\n","    xt = (xt + 1) / 2\n","\n","    return xt"],"metadata":{"id":"Cn5D0hbEU3Gq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load model and config\n","cfg = CONFIG()\n","\n","# Generate\n","generated_imgs = []\n","for i in tqdm(range(cfg.num_img_to_generate)):\n","    xt = generate(cfg)\n","    xt = 255 * xt[0][0].numpy()\n","    generated_imgs.append(xt.astype(np.uint8).flatten())\n","\n","# Save Generated Data CSV\n","generated_df = pd.DataFrame(generated_imgs, columns=[f'pixel{i}' for i in range(784)])\n","generated_df.to_csv(cfg.generated_csv_path, index=False)\n","\n","# Visualize\n","from matplotlib import pyplot as plt\n","fig, axes = plt.subplots(8, 8, figsize=(5, 5))\n","\n","# Plot each image in the corresponding subplot\n","for i, ax in enumerate(axes.flat):\n","    ax.imshow(np.reshape(generated_imgs[i], (28, 28)), cmap='gray')  # You might need to adjust the colormap based on your images\n","    ax.axis('off')  # Turn off axis labels\n","\n","plt.tight_layout()  # Adjust spacing between subplots\n","plt.show()"],"metadata":{"id":"BoNJ0QHol3nz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_activation(dataloader,\n","                   model,\n","                   preprocess, # Preprocessing Transform for InceptionV3\n","                   device = 'cpu'\n","                  ):\n","    \"\"\"\n","    Given Dataloader and Model, Generate N X 2048\n","    Dimensional activation map for N data points\n","    in dataloader.\n","    \"\"\"\n","\n","    # Set model to evaluation Mode\n","    model.to(device)\n","    model.eval()\n","\n","    # Save activations\n","    pred_arr = np.zeros((len(dataloader.dataset), 2048))\n","\n","    # Batch Size\n","    batch_size = dataloader.batch_size\n","\n","    # Loop over Dataloader\n","    with torch.no_grad():\n","        for i, batch in tqdm(enumerate(dataloader)):\n","\n","            # Transform the Batch according to Inceptionv3 specification\n","            batch = torch.stack([preprocess(img) for img in batch]).to(device)\n","\n","            # Predict\n","            pred = model(batch).cpu().numpy()\n","\n","            # Store\n","            pred_arr[i*batch_size : i*batch_size + batch.size(0), :] = pred\n","\n","    return pred_arr\n","\n","def calculate_activation_statistics(dataloader,\n","                                    model,\n","                                    preprocess,\n","                                    device='cpu'\n","                                   ):\n","    \"\"\"\n","    Get mean vector and covariance matrix of the activation maps.\n","    \"\"\"\n","\n","    # Get activation maps\n","    act = get_activation(dataloader,\n","                         model,\n","                         preprocess, # Preprocessing Transform for InceptionV3\n","                         device\n","                       )\n","    # Mean\n","    mu = np.mean(act, axis=0)\n","\n","    # Covariance Metric\n","    sigma = np.cov(act, rowvar=False)\n","\n","    return mu, sigma\n","\n","from scipy import linalg\n","\n","def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n","\n","    \"\"\"\n","    Given Mean and Sigma of Real and Generated Data,\n","    it calculates FID between them using:\n","\n","     d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n","\n","    \"\"\"\n","    # Make sure they have appropriate dims\n","    mu1 = np.atleast_1d(mu1)\n","    mu2 = np.atleast_1d(mu2)\n","\n","    sigma1 = np.atleast_2d(sigma1)\n","    sigma2 = np.atleast_2d(sigma2)\n","\n","    diff = mu1 - mu2\n","    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n","\n","    # Handle various cases\n","    if not np.isfinite(covmean).all():\n","        msg = (\n","            \"fid calculation produces singular product; \"\n","            \"adding %s to diagonal of cov estimates\"\n","        ) % eps\n","        print(msg)\n","        offset = np.eye(sigma1.shape[0]) * eps\n","        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n","\n","    # Numerical error might give slight imaginary component\n","    if np.iscomplexobj(covmean):\n","        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n","            m = np.max(np.abs(covmean.imag))\n","            raise ValueError(\"Imaginary component {}\".format(m))\n","        covmean = covmean.real\n","\n","    tr_covmean = np.trace(covmean)\n","\n","    return diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean"],"metadata":{"id":"p-0Pz4lNmXhM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Transform to Convert Output of CustomMnistDataset class to Inception format.\n","import torchvision.transforms as transforms\n","\n","transform_inception = transforms.Compose([\n","    transforms.Lambda(lambda x: (x + 1.0)/2.0), # [-1, 1] => [0, 1]\n","    transforms.ToPILImage(), # Tensor to PIL Image\n","    transforms.Resize((299, 299)),\n","    transforms.Grayscale(num_output_channels=3),  # Convert to RGB format\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization\n","\n","])\n","\n","# Load InceptionV3 Model\n","import torchvision.models as models\n","from torchvision.models.inception import Inception_V3_Weights\n","model = models.inception_v3(weights=Inception_V3_Weights.IMAGENET1K_V1)\n","model.fc = nn.Identity()\n","\n","# Mean and Sigma For Generated Data\n","mnist_ds = CustomMnistDataset(cfg.generated_csv_path, cfg.num_img_to_generate)\n","mnist_dl = DataLoader(mnist_ds, cfg.batch_size//4, shuffle=False)\n","mu1, sigma1 = calculate_activation_statistics(mnist_dl, model, preprocess = transform_inception, device='cuda')\n","\n","# Mean and Sigma for Test Data\n","mnist_ds = CustomMnistDataset(cfg.test_csv_path, cfg.num_img_to_generate)\n","mnist_dl = DataLoader(mnist_ds, cfg.batch_size//4, shuffle=False)\n","mu2, sigma2 = calculate_activation_statistics(mnist_dl, model, preprocess = transform_inception, device='cuda')\n","\n","# Calculate FID\n","fid = calculate_frechet_distance(mu1, sigma1, mu2, sigma2)\n","print(f'FID-Score: {fid}')"],"metadata":{"id":"p0vHpcSHmXyZ"},"execution_count":null,"outputs":[]}]}